{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5c7a994",
   "metadata": {},
   "source": [
    "DeFi BI-ETL Pipeline - Exploratory Data Analysis\n",
    "This file can be converted to a Jupyter notebook using:\n",
    "jupytext --to notebook exploration.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58380b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85401cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import get_processed_data_path, get_tableau_path\n",
    "from utils.time import utc_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220979a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DeFi BI-ETL Pipeline - Exploratory Data Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Analysis started at: {utc_now()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669f48b",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "1. LOAD AND EXPLORE DATA\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08af73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. LOADING AND EXPLORING DATA\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what data files are available\n",
    "processed_dir = Path(\"data/processed\")\n",
    "tableau_dir = Path(\"dashboards/tableau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5559df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available processed data files:\")\n",
    "if processed_dir.exists():\n",
    "    for csv_file in processed_dir.glob(\"*.csv\"):\n",
    "        print(f\"  - {csv_file.name}\")\n",
    "else:\n",
    "    print(\"  No processed data directory found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAvailable Tableau export files:\")\n",
    "if tableau_dir.exists():\n",
    "    for csv_file in tableau_dir.glob(\"*.csv\"):\n",
    "        print(f\"  - {csv_file.name}\")\n",
    "else:\n",
    "    print(\"  No Tableau export directory found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643a0a6",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "2. MARKETS DATA ANALYSIS\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2. MARKETS DATA ANALYSIS\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c077b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    markets_file = get_processed_data_path(\"cg_markets_latest.csv\")\n",
    "    if Path(markets_file).exists():\n",
    "        markets_df = pd.read_csv(markets_file)\n",
    "        print(f\"Markets data loaded: {len(markets_df)} records, {len(markets_df.columns)} columns\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"\\nMarket Cap Statistics:\")\n",
    "        print(f\"  Total Market Cap: ${markets_df['market_cap'].sum() / 1e9:.2f}B\")\n",
    "        print(f\"  Average Market Cap: ${markets_df['market_cap'].mean() / 1e9:.2f}B\")\n",
    "        print(f\"  Median Market Cap: ${markets_df['market_cap'].median() / 1e9:.2f}B\")\n",
    "        \n",
    "        # Top 10 by market cap\n",
    "        print(f\"\\nTop 10 Cryptocurrencies by Market Cap:\")\n",
    "        top_10 = markets_df.nlargest(10, 'market_cap')[['symbol', 'name', 'market_cap', 'pct_24h']]\n",
    "        for _, row in top_10.iterrows():\n",
    "            market_cap_b = row['market_cap'] / 1e9\n",
    "            pct_change = row['pct_24h']\n",
    "            print(f\"  {row['symbol']:>8} ({row['name'][:20]:<20}) ${market_cap_b:>8.2f}B  {pct_change:>6.2f}%\")\n",
    "        \n",
    "        # Price change distribution\n",
    "        print(f\"\\n24h Price Change Distribution:\")\n",
    "        pct_24h = markets_df['pct_24h'].dropna()\n",
    "        print(f\"  Mean: {pct_24h.mean():.2f}%\")\n",
    "        print(f\"  Median: {pct_24h.median():.2f}%\")\n",
    "        print(f\"  Std: {pct_24h.std():.2f}%\")\n",
    "        print(f\"  Min: {pct_24h.min():.2f}%\")\n",
    "        print(f\"  Max: {pct_24h.max():.2f}%\")\n",
    "        \n",
    "        # Volume analysis\n",
    "        print(f\"\\nVolume Analysis:\")\n",
    "        total_volume = markets_df['total_volume'].sum()\n",
    "        print(f\"  Total 24h Volume: ${total_volume / 1e9:.2f}B\")\n",
    "        print(f\"  Volume/Market Cap Ratio: {(total_volume / markets_df['market_cap'].sum()):.2%}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Markets data file not found\")\n",
    "        markets_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409fab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "except Exception as e:\n",
    "    print(f\"Error loading markets data: {e}\")\n",
    "    markets_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31406872",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024cd11",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "3. CATEGORIES DATA ANALYSIS\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f76499",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"3. CATEGORIES DATA ANALYSIS\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    categories_file = get_processed_data_path(\"cg_categories_snapshot.csv\")\n",
    "    if Path(categories_file).exists():\n",
    "        categories_df = pd.read_csv(categories_file)\n",
    "        print(f\"Categories data loaded: {len(categories_df)} records, {len(categories_df.columns)} columns\")\n",
    "        \n",
    "        # Market cap by category\n",
    "        print(f\"\\nMarket Cap by Category:\")\n",
    "        category_mcap = categories_df.groupby('name')['market_cap'].sum().sort_values(ascending=False)\n",
    "        for category, mcap in category_mcap.head(10).items():\n",
    "            mcap_b = mcap / 1e9\n",
    "            print(f\"  {category[:30]:<30} ${mcap_b:>8.2f}B\")\n",
    "        \n",
    "        # Category distribution\n",
    "        total_mcap = categories_df['market_cap'].sum()\n",
    "        print(f\"\\nCategory Market Share:\")\n",
    "        for category, mcap in category_mcap.head(10).items():\n",
    "            share = (mcap / total_mcap) * 100\n",
    "            print(f\"  {category[:30]:<30} {share:>6.2f}%\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Categories data file not found\")\n",
    "        categories_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "except Exception as e:\n",
    "    print(f\"Error loading categories data: {e}\")\n",
    "    categories_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a30562",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "4. TVL DATA ANALYSIS\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748368e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"4. TVL DATA ANALYSIS\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tvl_file = get_processed_data_path(\"llama_tvl_protocols.csv\")\n",
    "    if Path(tvl_file).exists():\n",
    "        tvl_df = pd.read_csv(tvl_file)\n",
    "        print(f\"TVL data loaded: {len(tvl_df)} records, {len(tvl_df.columns)} columns\")\n",
    "        \n",
    "        # Top protocols by TVL\n",
    "        print(f\"\\nTop 10 Protocols by TVL:\")\n",
    "        top_tvl = tvl_df.nlargest(10, 'tvl_usd')[['protocol_name', 'tvl_usd', 'change_1d']]\n",
    "        for _, row in top_tvl.iterrows():\n",
    "            tvl_b = row['tvl_usd'] / 1e9\n",
    "            change_1d = row['change_1d']\n",
    "            print(f\"  {row['protocol_name'][:25]:<25} ${tvl_b:>8.2f}B  {change_1d:>6.2f}%\")\n",
    "        \n",
    "        # TVL statistics\n",
    "        print(f\"\\nTVL Statistics:\")\n",
    "        print(f\"  Total TVL: ${tvl_df['tvl_usd'].sum() / 1e9:.2f}B\")\n",
    "        print(f\"  Average TVL: ${tvl_df['tvl_usd'].mean() / 1e9:.2f}B\")\n",
    "        print(f\"  Median TVL: ${tvl_df['tvl_usd'].median() / 1e9:.2f}B\")\n",
    "        \n",
    "        # 24h change analysis\n",
    "        change_1d = tvl_df['change_1d'].dropna()\n",
    "        print(f\"\\n24h TVL Change Distribution:\")\n",
    "        print(f\"  Mean: {change_1d.mean():.2f}%\")\n",
    "        print(f\"  Median: {change_1d.median():.2f}%\")\n",
    "        print(f\"  Positive changes: {(change_1d > 0).sum()} protocols\")\n",
    "        print(f\"  Negative changes: {(change_1d < 0).sum()} protocols\")\n",
    "        \n",
    "    else:\n",
    "        print(\"TVL data file not found\")\n",
    "        tvl_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "except Exception as e:\n",
    "    print(f\"Error loading TVL data: {e}\")\n",
    "    tvl_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35bb219",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "5. HISTORICAL TVL ANALYSIS\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1495af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"5. HISTORICAL TVL ANALYSIS\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784675f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tvl_hist_file = get_processed_data_path(\"llama_tvl_protocols_30d.csv\")\n",
    "    if Path(tvl_hist_file).exists():\n",
    "        tvl_hist_df = pd.read_csv(tvl_hist_file)\n",
    "        print(f\"Historical TVL data loaded: {len(tvl_hist_df)} records, {len(tvl_hist_df.columns)} columns\")\n",
    "        \n",
    "        # Convert date column\n",
    "        tvl_hist_df['date'] = pd.to_datetime(tvl_hist_df['date'])\n",
    "        \n",
    "        # Date range\n",
    "        print(f\"\\nData Date Range:\")\n",
    "        print(f\"  Start: {tvl_hist_df['date'].min().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"  End: {tvl_hist_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"  Days: {(tvl_hist_df['date'].max() - tvl_hist_df['date'].min()).days}\")\n",
    "        \n",
    "        # Protocols covered\n",
    "        protocols = tvl_hist_df['protocol_name'].nunique()\n",
    "        print(f\"\\nProtocols covered: {protocols}\")\n",
    "        \n",
    "        # TVL trend analysis\n",
    "        print(f\"\\nTVL Trend Analysis:\")\n",
    "        daily_tvl = tvl_hist_df.groupby('date')['tvl_usd'].sum()\n",
    "        print(f\"  First day total TVL: ${daily_tvl.iloc[0] / 1e9:.2f}B\")\n",
    "        print(f\"  Last day total TVL: ${daily_tvl.iloc[-1] / 1e9:.2f}B\")\n",
    "        \n",
    "        if len(daily_tvl) > 1:\n",
    "            total_change = ((daily_tvl.iloc[-1] - daily_tvl.iloc[0]) / daily_tvl.iloc[0]) * 100\n",
    "            print(f\"  Total change: {total_change:+.2f}%\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Historical TVL data file not found\")\n",
    "        tvl_hist_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "except Exception as e:\n",
    "    print(f\"Error loading historical TVL data: {e}\")\n",
    "    tvl_hist_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16db0f",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "6. DATA QUALITY ASSESSMENT\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"6. DATA QUALITY ASSESSMENT\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ab027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "if markets_df is not None:\n",
    "    print(\"Markets Data Quality:\")\n",
    "    missing_data = markets_df.isnull().sum()\n",
    "    if missing_data.sum() > 0:\n",
    "        print(\"  Missing values found:\")\n",
    "        for col, missing in missing_data[missing_data > 0].items():\n",
    "            print(f\"    {col}: {missing} ({missing/len(markets_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  No missing values found\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = markets_df.duplicated(subset=['id']).sum()\n",
    "    print(f\"  Duplicate records: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tvl_df is not None:\n",
    "    print(\"\\nTVL Data Quality:\")\n",
    "    missing_data = tvl_df.isnull().sum()\n",
    "    if missing_data.sum() > 0:\n",
    "        print(\"  Missing values found:\")\n",
    "        for col, missing in missing_data[missing_data > 0].items():\n",
    "            print(f\"    {col}: {missing} ({missing/len(tvl_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"  No missing values found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123eba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812efb37",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "7. SUMMARY AND RECOMMENDATIONS\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa087ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"7. SUMMARY AND RECOMMENDATIONS\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Pipeline Status:\")\n",
    "if markets_df is not None:\n",
    "    print(\"  ✓ Markets data available\")\n",
    "if categories_df is not None:\n",
    "    print(\"  ✓ Categories data available\")\n",
    "if tvl_df is not None:\n",
    "    print(\"  ✓ TVL data available\")\n",
    "if tvl_hist_df is not None:\n",
    "    print(\"  ✓ Historical TVL data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRecommendations:\")\n",
    "print(\"  1. Run 'python -m src.cli quickrun' to ensure all data is up to date\")\n",
    "print(\"  2. Check data freshness - ensure files are from today\")\n",
    "print(\"  3. Validate data ranges - look for unusual values\")\n",
    "print(\"  4. Monitor API rate limits and errors\")\n",
    "print(\"  5. Consider adding data validation rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nAnalysis completed at: {utc_now()}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d89e4",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "8. PLOTTING FUNCTIONS (commented out for CLI usage)\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Uncomment these functions if running in Jupyter notebook\n",
    "\n",
    "def plot_market_cap_distribution(df):\n",
    "    '''Plot market cap distribution.'''\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Log scale for better visualization\n",
    "    plt.hist(df['market_cap'] / 1e9, bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Market Cap (Billions USD)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Cryptocurrency Market Caps')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def plot_price_changes(df):\n",
    "    '''Plot 24h price changes.'''\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.hist(df['pct_24h'].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('24h Price Change (%)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of 24h Price Changes')\n",
    "    plt.axvline(x=0, color='red', linestyle='--', alpha=0.7)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_markets(df, top_n=20):\n",
    "    '''Plot top markets by market cap.'''\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    top_markets = df.nlargest(top_n, 'market_cap')\n",
    "    \n",
    "    plt.barh(range(len(top_markets)), top_markets['market_cap'] / 1e9)\n",
    "    plt.yticks(range(len(top_markets)), top_markets['symbol'])\n",
    "    plt.xlabel('Market Cap (Billions USD)')\n",
    "    plt.title(f'Top {top_n} Cryptocurrencies by Market Cap')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_tvl_trends(df):\n",
    "    '''Plot TVL trends over time.'''\n",
    "    if 'date' not in df.columns:\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Group by date and protocol\n",
    "    daily_tvl = df.groupby(['date', 'protocol_name'])['tvl_usd'].sum().unstack()\n",
    "    \n",
    "    # Plot top 5 protocols\n",
    "    top_protocols = daily_tvl.sum().nlargest(5).index\n",
    "    daily_tvl[top_protocols].plot(figsize=(14, 8))\n",
    "    \n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('TVL (USD)')\n",
    "    plt.title('TVL Trends for Top Protocols')\n",
    "    plt.legend(title='Protocol')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# if markets_df is not None:\n",
    "#     plot_market_cap_distribution(markets_df)\n",
    "#     plot_price_changes(markets_df)\n",
    "#     plot_top_markets(markets_df)\n",
    "\n",
    "# if tvl_hist_df is not None:\n",
    "#     plot_tvl_trends(tvl_hist_df)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
